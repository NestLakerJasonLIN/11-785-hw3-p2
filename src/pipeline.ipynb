{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "pipeline.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XBs-7kErwZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52YE7Srpr4aq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp drive/My\\ Drive/11785/hw3_p2/phoneme_list.py .\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget\n",
        "%cd ctcdecode\n",
        "!pip install .\n",
        "%cd ..\n",
        "!pip install python-Levenshtein"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCVDMHLerlrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import phoneme_list\n",
        "import ctcdecode\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import Levenshtein\n",
        "import os\n",
        "\n",
        "verbose = True\n",
        "mode = \"actual\"\n",
        "cuda = torch.cuda.is_available()\n",
        "num_workers = 4 if cuda else 0 \n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe2Ssxvgrlr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if verbose:\n",
        "    print(\"mode: %s\" % mode)\n",
        "    print(\"torch version: %s\" % torch.__version__)\n",
        "    print(\"np version: %s\" % np.__version__)\n",
        "    print(\"cuda: %s\" % cuda)\n",
        "    print(\"num_workers: %s\" % num_workers)\n",
        "    print(\"device: %s\" % device)\n",
        "    print(\"verbose: %s\" % verbose)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV22a0DArlr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_path = \"drive/My Drive/11785/hw3_p2/pred/\"\n",
        "data_path = \"drive/My Drive/11785/hw3_p2/hw3p2/\"\n",
        "checkpoint_path = \"drive/My Drive/11785/hw3_p2/checkpoint/\"\n",
        "\n",
        "ID = 1\n",
        "checkpoint_filename = checkpoint_path + \"checkpoint_%d.tar\" % ID\n",
        "pred_filename = pred_path + \"pred.csv\"\n",
        "\n",
        "train_path = data_path + \"wsj0_train\"\n",
        "dev_path = data_path + \"wsj0_dev.npy\"\n",
        "test_path = data_path + \"wsj0_test\"\n",
        "train_merged_labels_path = data_path + \"wsj0_train_merged_labels.npy\"\n",
        "dev_merged_labels_path = data_path + \"wsj0_dev_merged_labels.npy\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5_opj7trlr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if mode == 'actual':\n",
        "    train = np.load(train_path, allow_pickle=True)\n",
        "    train_merged_labels = np.load(train_merged_labels_path, allow_pickle=True)\n",
        "else:\n",
        "    train = np.load(dev_path, allow_pickle=True)\n",
        "    train_merged_labels = np.load(dev_merged_labels_path, allow_pickle=True)\n",
        "\n",
        "dev = np.load(dev_path, allow_pickle=True)\n",
        "dev_merged_labels = np.load(dev_merged_labels_path, allow_pickle=True)\n",
        "test = np.load(test_path, allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlO0G9Udrlr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class simpleDataset(Dataset):\n",
        "    def __init__(self, x, y=None, is_test=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.is_test = is_test\n",
        "        self._x = x\n",
        "        self._y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._x)\n",
        "      \n",
        "    def __getitem__(self, index):\n",
        "        if not self.is_test:\n",
        "            return torch.from_numpy(self._x[index]).float(), torch.from_numpy(self._y[index])\n",
        "        else:\n",
        "            return torch.from_numpy(self._x[index]).float()\n",
        "\n",
        "# customize pinned memory for fast host-gpu copies\n",
        "class CustomBatch:\n",
        "    def __init__(self, batch, is_test=False):\n",
        "        # reference: https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html\n",
        "        if not is_test:\n",
        "            data, target = zip(*batch)\n",
        "\n",
        "            self.data_lens = [len(x) for x in data]\n",
        "            self.target_lens = [len(y) for y in target]\n",
        "\n",
        "            self.data = pad_sequence(data, batch_first=True)\n",
        "            self.target = pad_sequence(target, batch_first=True)\n",
        "        else:\n",
        "            data = batch\n",
        "            self.data_lens = [len(x) for x in data]\n",
        "            self.data = pad_sequence(data, batch_first=True)\n",
        "            self.target = None\n",
        "\n",
        "    # custom memory pinning method on custom type\n",
        "    def pin_memory(self):\n",
        "        # TODO: check if this really works\n",
        "        self.data = self.data.pin_memory()\n",
        "        if self.target is not None:\n",
        "            self.target = self.target.pin_memory()\n",
        "        return self\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return CustomBatch(batch)\n",
        "\n",
        "def collate_fn_test(batch):\n",
        "    return CustomBatch(batch, is_test=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L3NClZDrlr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = simpleDataset(train, train_merged_labels)\n",
        "dev_dataset = simpleDataset(dev, dev_merged_labels)\n",
        "test_dataset = simpleDataset(test, is_test=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCQ4gAGtrlsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyper-parameters\n",
        "batch_size = 128\n",
        "input_size = 40\n",
        "hidden_size = 512\n",
        "output_size = 47\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "bidirectional = True\n",
        "lr = 0.05\n",
        "beam_size = 10\n",
        "blank_idx = 46\n",
        "epochs = 100\n",
        "\n",
        "# decoding-related\n",
        "# TODO: use what to represent blank symbol ?\n",
        "vocab = phoneme_list.PHONEME_MAP + ['#']\n",
        "decoder = ctcdecode.CTCBeamDecoder(labels=vocab, \n",
        "                                   beam_width=beam_size,\n",
        "                                   blank_id=blank_idx,\n",
        "                                   log_probs_input=True,\n",
        "                                   num_processes = os.cpu_count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWlkv047rlsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(\n",
        "                train_dataset,              # The dataset\n",
        "                batch_size=batch_size,      # Batch size\n",
        "                shuffle=True,               # Shuffles the dataset at every epoch\n",
        "                pin_memory=True,            # Copy data to CUDA pinned memory\n",
        "                num_workers=num_workers,    # Number of worker processes for loading data.\n",
        "                collate_fn = collate_fn\n",
        "               )\n",
        "\n",
        "dev_loader = DataLoader(\n",
        "                dev_dataset,              # The dataset\n",
        "                batch_size=batch_size,      # Batch size\n",
        "                shuffle=False,               # Shuffles the dataset at every epoch\n",
        "                pin_memory=True,            # Copy data to CUDA pinned memory\n",
        "                num_workers=num_workers,    # Number of worker processes for loading data.\n",
        "                collate_fn = collate_fn\n",
        "               )\n",
        "\n",
        "test_loader = DataLoader(\n",
        "                test_dataset,              # The dataset\n",
        "                batch_size=batch_size,      # Batch size\n",
        "                shuffle=False,               # Shuffles the dataset at every epoch\n",
        "                pin_memory=True,            # Copy data to CUDA pinned memory\n",
        "                num_workers=num_workers,    # Number of worker processes for loading data.\n",
        "                collate_fn = collate_fn_test\n",
        "               )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKniY19arlsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Baseline(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, bidirectional, dropout):\n",
        "        super(Baseline, self).__init__()\n",
        "        \n",
        "        self.rnn = nn.LSTM(input_size=input_size, \n",
        "                          hidden_size=hidden_size,\n",
        "                          num_layers = num_layers,\n",
        "                          batch_first = True,\n",
        "                          dropout = dropout,\n",
        "                          bidirectional = bidirectional\n",
        "                          )\n",
        "        \n",
        "        self.linear = nn.Linear(hidden_size*2, output_size)\n",
        "\n",
        "    def forward(self, data, data_lens):\n",
        "        # pack too rnn\n",
        "        data_packed = pack_padded_sequence(data, data_lens, batch_first=True, enforce_sorted=False)\n",
        "        \n",
        "        output_packed, (hn, cn) = self.rnn(data_packed)\n",
        "        \n",
        "        # unpack from rnn\n",
        "        output_padded, output_lengths = pad_packed_sequence(output_packed, batch_first=True)\n",
        "\n",
        "        # output shape: (batch_size, seq_len, output_size)\n",
        "        output = self.linear(output_padded)\n",
        "\n",
        "        # TODO: softmax considered packed value which should not be considered\n",
        "        # do softmax before pass to CTC loss\n",
        "        output = F.log_softmax(output, dim=-1)\n",
        "\n",
        "        return output, output_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RwjzzN2rlsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_string(tokens, vocab, seq_len):\n",
        "    return ''.join([vocab[x] for x in tokens[0:seq_len]])\n",
        "\n",
        "def decode_beam_result(batch_tokens, vocab, batch_seq_lens):\n",
        "    decode_strs = []\n",
        "    for idx, tokens in enumerate(batch_tokens):\n",
        "        decode_str = convert_to_string(tokens, vocab, batch_seq_lens[idx])\n",
        "        decode_strs.append(decode_str)\n",
        "\n",
        "    return decode_strs\n",
        "\n",
        "\n",
        "def decode(decoder, vocab, outputs, target, output_lens, target_lens):\n",
        "    # outputs: log_softmax output from model\n",
        "    \n",
        "    # step1: CTC beamsearch\n",
        "    beam_result, beam_scores, timesteps, beam_output_lens \\\n",
        "        = decoder.decode(outputs, seq_lens=output_lens)\n",
        "    \n",
        "    # step2: decode\n",
        "    preds = decode_beam_result(beam_result[:, 0, :], vocab, beam_output_lens[:, 0])\n",
        "    if (target is not None and target_lens is not None):\n",
        "        golds = decode_beam_result(target, vocab, target_lens)\n",
        "    else:\n",
        "        golds = None\n",
        "\n",
        "    return (preds, golds)\n",
        "\n",
        "# TODO: detach for dev\n",
        "def get_edit_distances(preds, golds):\n",
        "    sum_edit_dists = 0\n",
        "    for idx, pred in enumerate(preds):\n",
        "        # calculate Levenshtein distance as accuracy\n",
        "        edit_dist = Levenshtein.distance(pred, golds[idx])\n",
        "        sum_edit_dists +=edit_dist\n",
        "    \n",
        "    return sum_edit_dists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddgamZ28rlsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, device, decoder, vocab):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total_samples = 0\n",
        "    total_edit_distance = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for batch_idx, sample in enumerate(tqdm(train_loader)):\n",
        "        data, target = sample.data, sample.target\n",
        "        data_lens, target_lens = sample.data_lens, sample.target_lens\n",
        "        assert data.shape[1] == max(data_lens)\n",
        "        assert target.shape[1] == max(target_lens)\n",
        "        \n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs, output_lens = model(data, data_lens)\n",
        "\n",
        "        loss = criterion(log_probs = outputs.permute(1, 0, 2), \n",
        "              targets = target, \n",
        "              input_lengths = output_lens, \n",
        "              target_lengths = torch.tensor(target_lens))\n",
        "  \n",
        "        running_loss += loss.item()\n",
        "        total_samples += target.size(0)\n",
        "        total_edit_distance += get_edit_distances(*decode(decoder, vocab, \n",
        "                                                  outputs, target, \n",
        "                                                  output_lens, \n",
        "                                                  target_lens))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    running_loss /= len(train_loader)\n",
        "    acc = (total_edit_distance / total_samples)\n",
        "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
        "    print('Training Accuracy (edit distance): ', acc)\n",
        "    \n",
        "    return running_loss, acc\n",
        "\n",
        "def evaluate_model(model, eval_loader, criterion, device, decoder, vocab):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        total_samples = 0\n",
        "        total_edit_distance = 0\n",
        "\n",
        "        for batch_idx, sample in enumerate(tqdm(eval_loader)):\n",
        "            data, target = sample.data, sample.target\n",
        "            data_lens, target_lens = sample.data_lens, sample.target_lens\n",
        "            assert data.shape[1] == max(data_lens)\n",
        "            assert target.shape[1] == max(target_lens)\n",
        "\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            outputs, output_lens = model(data, data_lens)\n",
        "\n",
        "            loss = criterion(log_probs = outputs.permute(1, 0, 2), \n",
        "                              targets = target, \n",
        "                              input_lengths = output_lens, \n",
        "                              target_lengths = torch.tensor(target_lens)).detach()\n",
        "  \n",
        "            running_loss += loss.item()\n",
        "            total_samples += target.size(0)\n",
        "            total_edit_distance += get_edit_distances(*decode(decoder, vocab, \n",
        "                                                      outputs, target, \n",
        "                                                      output_lens, \n",
        "                                                      target_lens))\n",
        "\n",
        "        running_loss /= len(eval_loader)\n",
        "        acc = (total_edit_distance / total_samples)\n",
        "        print('evaluate Loss: ', running_loss)\n",
        "        print('evaluate Accuracy (edit distance): ', acc)\n",
        "        return running_loss, acc\n",
        "\n",
        "def train_model(model, epochs, train_loader, eval_loader, criterion, optimizer, device, decoder, vocab, scheduler=None, checkpoint_filename=None):\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"epoch: %d\" % (epoch))\n",
        "        \n",
        "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device, decoder, vocab)\n",
        "        eval_loss, eval_acc = evaluate_model(model, eval_loader, criterion, device, decoder, vocab)\n",
        "        \n",
        "        if scheduler:\n",
        "            if type(scheduler) is optim.lr_scheduler.StepLR:\n",
        "                scheduler.step()\n",
        "            elif type(scheduler) is optim.lr_scheduler.ReduceLROnPlateau:\n",
        "                scheduler.step(eval_loss)\n",
        "            else:\n",
        "                raise valueError(\"No such scheduler\")\n",
        "        \n",
        "        if checkpoint_filename:\n",
        "            checkpoint = {\n",
        "                \"model_state_dict\" : model.state_dict(),\n",
        "                \"optimizer_state_dict\" : optimizer.state_dict(),\n",
        "                \"scheduler_state_dict\" : scheduler.state_dict()\n",
        "            }\n",
        "            torch.save(checkpoint, checkpoint_filename)\n",
        "            print('model is saved to {}'.format(checkpoint_filename))\n",
        "        \n",
        "        print('=' * 20)\n",
        "    \n",
        "    return "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQZgo4FtrlsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, test_loader, device, decoder, vocab, save=False, filename=\"../data/test_pred.csv\"):\n",
        "    all_preds = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        model.to(device)\n",
        "\n",
        "        # no target in test dataset/data loader\n",
        "        for batch_idx, sample in enumerate(tqdm(test_loader)):\n",
        "            data = sample.data\n",
        "            data_lens = sample.data_lens\n",
        "            assert data.shape[1] == max(data_lens)\n",
        "\n",
        "            data = data.to(device)\n",
        "\n",
        "            outputs, output_lens = model(data, data_lens)\n",
        "\n",
        "            preds, golds = decode(decoder, vocab, outputs, None, output_lens, None)\n",
        "            \n",
        "            all_preds.extend(preds)\n",
        "\n",
        "    if save:\n",
        "        result = np.concatenate([np.arange(len(all_preds)).reshape(-1, 1),\n",
        "                                 np.array(all_preds).reshape(-1, 1)], axis=1)\n",
        "        np.savetxt(filename, result, fmt=\"%s\", delimiter=\",\", header=\"id,Predicted\", comments=\"\")\n",
        "\n",
        "    return all_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd9TwE4BrlsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Baseline(input_size, hidden_size, output_size, num_layers, bidirectional, dropout)\n",
        "optimizer = optim.SGD(model.to(device).parameters(), lr=lr, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
        "# optimizer = optim.Adam(model.to(device).parameters(), lr=0.01)\n",
        "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.98)\n",
        "criterion = nn.CTCLoss(blank=blank_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6xlb8Ho0VdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = torch.load(checkpoint_filename, map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pXnGv086wkEF",
        "colab": {}
      },
      "source": [
        "train_model(model, epochs, train_loader, dev_loader, \n",
        "            criterion, optimizer, device, decoder, vocab, scheduler, checkpoint_filename=checkpoint_filename)\n",
        "\n",
        "if verbose:\n",
        "    print(\"finished\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLNYydqVrlsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicts = test_model(model, test_loader, device, decoder, vocab, save=True, filename=pred_filename)\n",
        "\n",
        "if verbose:\n",
        "    print(\"finished\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O-SYHC_-6j8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to change lr in half way\n",
        "for params in optimizer.param_groups:\n",
        "  params['lr']=0.05\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.98)\n",
        "scheduler.get_last_lr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_7FfhYv-827",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler.step()\n",
        "optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}