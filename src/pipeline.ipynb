{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "52YE7Srpr4aq"
   },
   "outputs": [],
   "source": [
    "# !git clone --recursive https://github.com/parlance/ctcdecode.git\n",
    "# !pip install wget\n",
    "# %cd ctcdecode\n",
    "# !pip install .\n",
    "# %cd ..\n",
    "# !pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zCVDMHLerlrw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import phoneme_list\n",
    "import ctcdecode\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import Levenshtein\n",
    "import os\n",
    "\n",
    "verbose = True\n",
    "mode = \"actual\"\n",
    "cuda = torch.cuda.is_available()\n",
    "num_workers = 4 if cuda else 0 \n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qe2Ssxvgrlr0"
   },
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    print(\"mode: %s\" % mode)\n",
    "    print(\"torch version: %s\" % torch.__version__)\n",
    "    print(\"np version: %s\" % np.__version__)\n",
    "    print(\"cuda: %s\" % cuda)\n",
    "    print(\"num_workers: %s\" % num_workers)\n",
    "    print(\"device: %s\" % device)\n",
    "    print(\"verbose: %s\" % verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eV22a0DArlr2"
   },
   "outputs": [],
   "source": [
    "pred_path = \"../pred/\"\n",
    "data_path = \"../data/\"\n",
    "checkpoint_path = \"../checkpoint/\"\n",
    "\n",
    "ID = 1\n",
    "checkpoint_filename = checkpoint_path + \"checkpoint_%d.tar\" % ID\n",
    "pred_filename = pred_path + \"pred.csv\"\n",
    "\n",
    "train_path = data_path + \"wsj0_train\"\n",
    "dev_path = data_path + \"wsj0_dev.npy\"\n",
    "test_path = data_path + \"wsj0_test\"\n",
    "train_merged_labels_path = data_path + \"wsj0_train_merged_labels.npy\"\n",
    "dev_merged_labels_path = data_path + \"wsj0_dev_merged_labels.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5_opj7trlr5"
   },
   "outputs": [],
   "source": [
    "if mode == 'actual':\n",
    "    train = np.load(train_path, allow_pickle=True)\n",
    "    train_merged_labels = np.load(train_merged_labels_path, allow_pickle=True)\n",
    "else:\n",
    "    train = np.load(dev_path, allow_pickle=True)\n",
    "    train_merged_labels = np.load(dev_merged_labels_path, allow_pickle=True)\n",
    "\n",
    "dev = np.load(dev_path, allow_pickle=True)\n",
    "dev_merged_labels = np.load(dev_merged_labels_path, allow_pickle=True)\n",
    "test = np.load(test_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BlO0G9Udrlr8"
   },
   "outputs": [],
   "source": [
    "class simpleDataset(Dataset):\n",
    "    def __init__(self, x, y=None, is_test=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.is_test = is_test\n",
    "        self._x = x\n",
    "        self._y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._x)\n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        if not self.is_test:\n",
    "            return torch.from_numpy(self._x[index]).float(), torch.from_numpy(self._y[index])\n",
    "        else:\n",
    "            return torch.from_numpy(self._x[index]).float()\n",
    "\n",
    "# customize pinned memory for fast host-gpu copies\n",
    "class CustomBatch:\n",
    "    def __init__(self, batch, is_test=False):\n",
    "        # reference: https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html\n",
    "        if not is_test:\n",
    "            data, target = zip(*batch)\n",
    "\n",
    "            self.data_lens = [len(x) for x in data]\n",
    "            self.target_lens = [len(y) for y in target]\n",
    "\n",
    "            self.data = pad_sequence(data, batch_first=True)\n",
    "            self.target = pad_sequence(target, batch_first=True)\n",
    "        else:\n",
    "            data = batch\n",
    "            self.data_lens = [len(x) for x in data]\n",
    "            self.data = pad_sequence(data, batch_first=True)\n",
    "            self.target = None\n",
    "\n",
    "    # custom memory pinning method on custom type\n",
    "    def pin_memory(self):\n",
    "        self.data = self.data.pin_memory()\n",
    "        if self.target is not None:\n",
    "            self.target = self.target.pin_memory()\n",
    "        return self\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return CustomBatch(batch)\n",
    "\n",
    "def collate_fn_test(batch):\n",
    "    return CustomBatch(batch, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3L3NClZDrlr_"
   },
   "outputs": [],
   "source": [
    "train_dataset = simpleDataset(train, train_merged_labels)\n",
    "dev_dataset = simpleDataset(dev, dev_merged_labels)\n",
    "test_dataset = simpleDataset(test, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCQ4gAGtrlsC"
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "batch_size = 128\n",
    "input_size = 40\n",
    "hidden_size = 512\n",
    "output_size = 47\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "bidirectional = True\n",
    "lr = 0.05\n",
    "beam_size = 10\n",
    "blank_idx = 46\n",
    "epochs = 100\n",
    "\n",
    "# decoding-related\n",
    "# TODO: use what to represent blank symbol ?\n",
    "vocab = phoneme_list.PHONEME_MAP + ['#']\n",
    "decoder = ctcdecode.CTCBeamDecoder(labels=vocab, \n",
    "                                   beam_width=beam_size,\n",
    "                                   blank_id=blank_idx,\n",
    "                                   log_probs_input=True,\n",
    "                                   num_processes = os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWlkv047rlsF"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "                train_dataset,              # The dataset\n",
    "                batch_size=batch_size,      # Batch size\n",
    "                shuffle=True,               # Shuffles the dataset at every epoch\n",
    "                pin_memory=True,            # Copy data to CUDA pinned memory\n",
    "                num_workers=num_workers,    # Number of worker processes for loading data.\n",
    "                collate_fn = collate_fn\n",
    "               )\n",
    "\n",
    "dev_loader = DataLoader(\n",
    "                dev_dataset,              # The dataset\n",
    "                batch_size=batch_size,      # Batch size\n",
    "                shuffle=False,               # Shuffles the dataset at every epoch\n",
    "                pin_memory=True,            # Copy data to CUDA pinned memory\n",
    "                num_workers=num_workers,    # Number of worker processes for loading data.\n",
    "                collate_fn = collate_fn\n",
    "               )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "                test_dataset,              # The dataset\n",
    "                batch_size=batch_size,      # Batch size\n",
    "                shuffle=False,               # Shuffles the dataset at every epoch\n",
    "                pin_memory=True,            # Copy data to CUDA pinned memory\n",
    "                num_workers=num_workers,    # Number of worker processes for loading data.\n",
    "                collate_fn = collate_fn_test\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKniY19arlsH"
   },
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, bidirectional, dropout):\n",
    "        super(Baseline, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers = num_layers,\n",
    "                          batch_first = True,\n",
    "                          dropout = dropout,\n",
    "                          bidirectional = bidirectional\n",
    "                          )\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size*2, output_size)\n",
    "\n",
    "    def forward(self, data, data_lens):\n",
    "        # pack too rnn\n",
    "        data_packed = pack_padded_sequence(data, data_lens, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        output_packed, (hn, cn) = self.rnn(data_packed)\n",
    "        \n",
    "        # unpack from rnn\n",
    "        output_padded, output_lengths = pad_packed_sequence(output_packed, batch_first=True)\n",
    "\n",
    "        # output shape: (batch_size, seq_len, output_size)\n",
    "        output = self.linear(output_padded)\n",
    "\n",
    "        output = F.log_softmax(output, dim=-1)\n",
    "\n",
    "        return output, output_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RwjzzN2rlsK"
   },
   "outputs": [],
   "source": [
    "def convert_to_string(tokens, vocab, seq_len):\n",
    "    return ''.join([vocab[x] for x in tokens[0:seq_len]])\n",
    "\n",
    "def decode_beam_result(batch_tokens, vocab, batch_seq_lens):\n",
    "    decode_strs = []\n",
    "    for idx, tokens in enumerate(batch_tokens):\n",
    "        decode_str = convert_to_string(tokens, vocab, batch_seq_lens[idx])\n",
    "        decode_strs.append(decode_str)\n",
    "\n",
    "    return decode_strs\n",
    "\n",
    "\n",
    "def decode(decoder, vocab, outputs, target, output_lens, target_lens):\n",
    "    # outputs: log_softmax output from model    \n",
    "    # step1: CTC beamsearch\n",
    "    beam_result, beam_scores, timesteps, beam_output_lens \\\n",
    "        = decoder.decode(outputs, seq_lens=output_lens)\n",
    "    \n",
    "    # step2: decode\n",
    "    preds = decode_beam_result(beam_result[:, 0, :], vocab, beam_output_lens[:, 0])\n",
    "    if (target is not None and target_lens is not None):\n",
    "        golds = decode_beam_result(target, vocab, target_lens)\n",
    "    else:\n",
    "        golds = None\n",
    "\n",
    "    return (preds, golds)\n",
    "\n",
    "def get_edit_distances(preds, golds):\n",
    "    sum_edit_dists = 0\n",
    "    for idx, pred in enumerate(preds):\n",
    "        # calculate Levenshtein distance as accuracy\n",
    "        edit_dist = Levenshtein.distance(pred, golds[idx])\n",
    "        sum_edit_dists +=edit_dist\n",
    "    return sum_edit_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddgamZ28rlsP"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, decoder, vocab):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    total_edit_distance = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_idx, sample in enumerate(tqdm(train_loader)):\n",
    "        data, target = sample.data, sample.target\n",
    "        data_lens, target_lens = sample.data_lens, sample.target_lens\n",
    "        assert data.shape[1] == max(data_lens)\n",
    "        assert target.shape[1] == max(target_lens)\n",
    "        \n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, output_lens = model(data, data_lens)\n",
    "\n",
    "        loss = criterion(log_probs = outputs.permute(1, 0, 2), \n",
    "              targets = target, \n",
    "              input_lengths = output_lens, \n",
    "              target_lengths = torch.tensor(target_lens))\n",
    "  \n",
    "        running_loss += loss.item()\n",
    "        total_samples += target.size(0)\n",
    "#         total_edit_distance += get_edit_distances(*decode(decoder, vocab, \n",
    "#                                                   outputs, target, \n",
    "#                                                   output_lens, \n",
    "#                                                   target_lens))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    running_loss /= len(train_loader)\n",
    "#     acc = (total_edit_distance / total_samples)\n",
    "    acc = 0\n",
    "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
    "#     print('Training Accuracy (edit distance): ', acc)\n",
    "    \n",
    "    return running_loss, acc\n",
    "\n",
    "def evaluate_model(model, eval_loader, criterion, device, decoder, vocab):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "        total_edit_distance = 0\n",
    "\n",
    "        for batch_idx, sample in enumerate(tqdm(eval_loader)):\n",
    "            data, target = sample.data, sample.target\n",
    "            data_lens, target_lens = sample.data_lens, sample.target_lens\n",
    "            assert data.shape[1] == max(data_lens)\n",
    "            assert target.shape[1] == max(target_lens)\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs, output_lens = model(data, data_lens)\n",
    "\n",
    "            loss = criterion(log_probs = outputs.permute(1, 0, 2), \n",
    "                              targets = target, \n",
    "                              input_lengths = output_lens, \n",
    "                              target_lengths = torch.tensor(target_lens)).detach()\n",
    "  \n",
    "            running_loss += loss.item()\n",
    "            total_samples += target.size(0)\n",
    "            total_edit_distance += get_edit_distances(*decode(decoder, vocab, \n",
    "                                                      outputs, target, \n",
    "                                                      output_lens, \n",
    "                                                      target_lens))\n",
    "\n",
    "        running_loss /= len(eval_loader)\n",
    "        acc = (total_edit_distance / total_samples)\n",
    "        print('evaluate Loss: ', running_loss)\n",
    "        print('evaluate Accuracy (edit distance): ', acc)\n",
    "        return running_loss, acc\n",
    "\n",
    "def train_model(model, epochs, train_loader, eval_loader, criterion, optimizer, device, decoder, vocab, scheduler=None, checkpoint_filename=None):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"epoch: %d\" % (epoch))\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, decoder, vocab)\n",
    "        eval_loss, eval_acc = evaluate_model(model, eval_loader, criterion, device, decoder, vocab)\n",
    "        \n",
    "        if scheduler:\n",
    "            if type(scheduler) is optim.lr_scheduler.StepLR:\n",
    "                scheduler.step()\n",
    "            elif type(scheduler) is optim.lr_scheduler.ReduceLROnPlateau:\n",
    "                scheduler.step(eval_loss)\n",
    "            else:\n",
    "                raise valueError(\"No such scheduler\")\n",
    "        \n",
    "        if checkpoint_filename:\n",
    "            checkpoint = {\n",
    "                \"model_state_dict\" : model.state_dict(),\n",
    "                \"optimizer_state_dict\" : optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\" : scheduler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, checkpoint_filename)\n",
    "            print('model is saved to {}'.format(checkpoint_filename))\n",
    "        \n",
    "        print('=' * 20)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IQZgo4FtrlsR"
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device, decoder, vocab, save=False, filename=\"../data/test_pred.csv\"):\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        # no target in test dataset/data loader\n",
    "        for batch_idx, sample in enumerate(tqdm(test_loader)):\n",
    "            data = sample.data\n",
    "            data_lens = sample.data_lens\n",
    "            assert data.shape[1] == max(data_lens)\n",
    "\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs, output_lens = model(data, data_lens)\n",
    "\n",
    "            preds, golds = decode(decoder, vocab, outputs, None, output_lens, None)\n",
    "            \n",
    "            all_preds.extend(preds)\n",
    "\n",
    "    if save:\n",
    "        result = np.concatenate([np.arange(len(all_preds)).reshape(-1, 1),\n",
    "                                 np.array(all_preds).reshape(-1, 1)], axis=1)\n",
    "        np.savetxt(filename, result, fmt=\"%s\", delimiter=\",\", header=\"id,Predicted\", comments=\"\")\n",
    "\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cd9TwE4BrlsT"
   },
   "outputs": [],
   "source": [
    "model = Baseline(input_size, hidden_size, output_size, num_layers, bidirectional, dropout)\n",
    "optimizer = optim.SGD(model.to(device).parameters(), lr=lr, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "# optimizer = optim.Adam(model.to(device).parameters(), lr=0.01)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.98)\n",
    "criterion = nn.CTCLoss(blank=blank_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y6xlb8Ho0VdE"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_filename, map_location=device)\n",
    "# checkpoint = torch.load(checkpoint_path + \"checkpoint_1_11-86.tar\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXnGv086wkEF",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_model(model, epochs, train_loader, dev_loader, \n",
    "            criterion, optimizer, device, decoder, vocab, scheduler, checkpoint_filename=checkpoint_filename)\n",
    "\n",
    "if verbose:\n",
    "    print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLNYydqVrlsY"
   },
   "outputs": [],
   "source": [
    "predicts = test_model(model, test_loader, device, decoder, vocab, save=True, filename=pred_filename)\n",
    "\n",
    "if verbose:\n",
    "    print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LeHJGNUhJxcB"
   },
   "source": [
    "## Debugging Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7O-SYHC_-6j8"
   },
   "outputs": [],
   "source": [
    "# to change lr in half way\n",
    "for params in optimizer.param_groups:\n",
    "    params['lr']=0.01\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.98)\n",
    "scheduler.get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_7FfhYv-827"
   },
   "outputs": [],
   "source": [
    "# scheduler.step()\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vB3vlN7ZDGAe"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oYuBPHHXG-wu"
   },
   "outputs": [],
   "source": [
    "# for batch_idx, sample in enumerate(tqdm(train_loader)):\n",
    "#       data, target = sample.data, sample.target\n",
    "#       data_lens, target_lens = sample.data_lens, sample.target_lens\n",
    "#       assert data.shape[1] == max(data_lens)\n",
    "#       assert target.shape[1] == max(target_lens)\n",
    "      \n",
    "#       data = data.to(device)\n",
    "#       target = target.to(device)\n",
    "\n",
    "#       outputs, output_lens = model(data, data_lens)\n",
    "\n",
    "#       loss = criterion(log_probs = outputs.permute(1, 0, 2), \n",
    "#             targets = target, \n",
    "#             input_lengths = output_lens, \n",
    "#             target_lengths = torch.tensor(target_lens))\n",
    "\n",
    "#       pred, golds = decode(decoder, vocab, \n",
    "#                                           outputs, target, \n",
    "#                                           output_lens, \n",
    "#                                           target_lens)\n",
    "#       total_edit_distance = get_edit_distances(pred, golds)\n",
    "#       break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fBKQKflWaL3P"
   },
   "outputs": [],
   "source": [
    "def test_model_ensemble(model_1, model_2, test_loader, device, decoder, vocab, save=False, filename=\"../data/test_pred.csv\"):\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        # no target in test dataset/data loader\n",
    "        for batch_idx, sample in enumerate(tqdm(test_loader)):\n",
    "            data = sample.data\n",
    "            data_lens = sample.data_lens\n",
    "            assert data.shape[1] == max(data_lens)\n",
    "\n",
    "            data = data.to(device)\n",
    "\n",
    "            outputs_1, output_lens_1 = model_1(data, data_lens)\n",
    "            outputs_2, output_lens_2 = model_2(data, data_lens)\n",
    "\n",
    "            outputs = 0.5 * outputs_1 + 0.5 * outputs_2\n",
    "            output_lens = output_lens_1\n",
    "\n",
    "            preds, golds = decode(decoder, vocab, outputs, None, output_lens, None)\n",
    "          \n",
    "            all_preds.extend(preds)\n",
    "\n",
    "        if save:\n",
    "            result = np.concatenate([np.arange(len(all_preds)).reshape(-1, 1),\n",
    "                                    np.array(all_preds).reshape(-1, 1)], axis=1)\n",
    "            np.savetxt(filename, result, fmt=\"%s\", delimiter=\",\", header=\"id,Predicted\", comments=\"\")\n",
    "\n",
    "        return all_preds  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWDLmggZfbrr"
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpYEVNgpfZFQ"
   },
   "outputs": [],
   "source": [
    "model_1_path, model_2_path = checkpoint_filename, checkpoint_path + \"checkpoint_1_11-86.tar\"\n",
    "\n",
    "model1 = Baseline(input_size, hidden_size, output_size, num_layers, bidirectional, dropout)\n",
    "checkpoint = torch.load(model_1_path, map_location=device)\n",
    "model1.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model2 = Baseline(input_size, hidden_size, output_size, num_layers, bidirectional, dropout)\n",
    "checkpoint = torch.load(model_2_path, map_location=device)\n",
    "model2.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnhOZeetddM2"
   },
   "outputs": [],
   "source": [
    "predicts = test_model_ensemble(model1, model2, test_loader, device, decoder, vocab, save=True, filename=pred_filename)\n",
    "\n",
    "if verbose:\n",
    "    print(\"finished ensemble\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
